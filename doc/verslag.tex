\documentclass[a4paper]{article}
\usepackage[noheadfoot, margin=3cm]{geometry}
\usepackage{graphicx}

\title{Stereo Vision using the OpenCV library}
\author{Sebastian Dr\"oppelmann \\ Moos Hueting \\ Sander Latour \\ Martijn van der Veen}
\date{June 2010}

\begin{document}

\begin{titlepage}
  \maketitle
\end{titlepage}

\section{Preface}
Stereo vision is one of the key subjects in the computer vision research. Stereo vision can be best described as taking two viewpoints in a 3D world, comparing the distance between the position of an object in both images and relating that to the distance of an object to the camera. Such information is retreived by a dense stereo algorithm of which the output is often a disparity depth map. A disparity depth map is a 2D image where the color of each pixel is directly linked to the distance of the pixel on that coordinate in the original image, in order words if an object is white it is depending on the implementation nearer or further away than a darker object. Our goal is to generate such a depth map from two images taken with two webcams.

Depthmaps are interesting because they can be used for various purposes: 
\begin{description}
 \item[3D modeling of 2D images] When you take two 2D images of a 3D enviroment and calculate the depthmap, you can create a 3D model of the scene by using the depth as the third dimension.
 \item[Tracking of objects] When you have a depthmap it is easier to track an object because you have additional segmentation possibilities. You can create segments of pixels that are near based on the depth of the pixels and their adjacency.
 \item[Recognising front objects] When you apply segmentation based on the depthmap, you can distinguish objects that are situated in the front of the scene.
 \item[As information about the environment in path planning] A depthmap supplies additional information for path planning.
\end{description}

\section{Practical problems}

\subsection{Webcams}
We will have to make the two webcams work on linux. Ideally we would have a live
feed from both webcams at all times.

\subsection{OpenCV}
We will have to get acquainted with the library OpenCV. See section
\ref{opencv}.

\section{Implementation}

\subsection{OpenCV}
\label{opencv}
OpenCV is a library of programming functions for real time computer vision. By using this library we can constrain our tasks to integrating various parts of OpenCV and expanding it where possible. If we would not use OpenCV, we would not have enough time to achieve our goal. OpenCV is a C library but has python binding which we will use to decrease the risk of programming errors.

\section{Theory}

\subsection{Epipolar geometry}
\label{epipolar}

\begin{figure}[h!]
  \label{fig:epipole}
  \centering
  \includegraphics[width=1.0\textwidth]{Epipolar_geometry}
  \caption{All points $X_{1}, X_{2}, \cdots, X_{L}$ lie on the same epipolar line in the right view}
\end{figure}

Epipolar geometry is used in stereo vision to limit the searching space when
looking for matching points in both images. A point $X$ in 3D space is seen in
image $A$ as a point $x$, which is on the line between camera $A$'s focal point
and point $X$. This line is seen by camera $B$ as a line. This is called an
\emph{epipolar line}. Given both the cameras internal and external matrices and
a point $x_A$ we can generate an epipolar line corresponding to this point in
image $B$. This constrains the search space to this 1D line.

The points called $e_{L}$ and $e_{R}$ in figure \ref{fig:epipole} are called the
\emph{epipolar points} of both images. Epipolar lines rotate around the epipolar
point of a given image.

For more information on epipolar geometry, see \cite{Hartley2004}.

\subsection{Rectification}
\label{rectification}
As we have seen in section \ref{epipolar}, we can constrain the search space to
a 1D line. However due to the nature computers store images, it would be very
convenient if these epipolar lines were parallel to the horizontal scanlines.
This is done by a process called \emph{rectification}. This process transforms
both images so that the epipolar lines of the images align horizontally. For
this, we need a matrix that relates the two cameras. This matrix is called the
\emph{fundamental matrix} or \emph{bifocal tensor} and is denoted by the symbol
$F$.

\subsubsection{Fundamental matrix}
Given a point $x$ in image $A$, $Fx$ describes the epipolar line in image
$B$ on which the corresponding point $x'$ must lie. This means that $F$ has to
satisfy the equation
\[ x'^{T}Fx = 0 \]
for all corresponding points $x$ and $x'$. Given enough corresponding points, we
can solve this equation linearly. The more points available, the more accurate
this fundamental matrix becomes.\footnote{That is, if the corresponding points
are accurate as well.}

\subsubsection{Chessboard points}
The corresponding points necessary for generating the fundamental matrix is
obtained by making multiple pictures of a chessboard in the environment. The
OpenCV toolkit has a builtin function to recognize the corners of a chessboard.
In this project we will not elaborate on that subject.

\newpage
\section{Planning}
\begin{itemize}
  \item Week 1
    \begin{itemize}
      \item Reading literature
      \item Getting webcams to work
      \item Choosing dense algorithm
    \end{itemize}
  \item Week 2 and 3
    \begin{itemize}
      \item Implementing
        \begin{itemize}
          \item Dense disparity map algorithm
          \item Camera calibration using epipolar geometry
          \item Rectification of images
        \end{itemize}
      \item Halfway report
    \end{itemize}
  \item Week 4
    \begin{itemize}
      \item Optimizing and testing
      \item If there's enough time left
        \begin{itemize}
          \item Generate 3D image of environment
          \item Remove background using dense disparity map
        \end{itemize}
    \end{itemize}
\end{itemize}

\section{Tasks}
  \begin{itemize}
    \item Martijn and Moos
    \begin{itemize}
      \item Camera calibration
      \item Epipolar geometry
    \end{itemize}
    \item Sander and Sebastian
    \begin{itemize}
      \item Finding corresponding points
      \item Generating depth map
    \end{itemize}
  \end{itemize}

\bibliographystyle{plain}
\bibliography{verslag}

\end{document}
